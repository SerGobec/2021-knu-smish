{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total size: 1571\nLegit messages: 1051\nSpam messages: 144\nSmishing messages: 376\nspam messages: 0\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"C:\\\\Elisabeth\\\\Универ\\\\Samsung_Smishing\\\\2021-knu-smish\\\\elizabeth_skvortsova\\\\data\\\\dataset.txt\"\n",
    "\n",
    "# give name to label-column and text-column\n",
    "COLUMN_LABEL = \"class\"\n",
    "COLUMN_TEXT = \"context\"\n",
    "\n",
    "# these are labels that indicate the type of message.\n",
    "LABEL_LEGIT = 'LEGI'\n",
    "LABEL_SPAM = 'SPAM'\n",
    "LABEL_SMISHING = 'SMIS'\n",
    "\n",
    "dataset = pd.read_csv(DATA_PATH, sep='\\t', names=[COLUMN_LABEL, COLUMN_TEXT], header=None)\n",
    "print('Total size:', dataset.shape[0])\n",
    "print('Legit messages:', dataset[dataset[COLUMN_LABEL] == LABEL_LEGIT].shape[0])\n",
    "print('Spam messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SPAM].shape[0])\n",
    "print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])\n",
    "\n",
    "\n",
    "dataset = dataset[((dataset[COLUMN_LABEL] == LABEL_LEGIT) | (dataset[COLUMN_LABEL] == LABEL_SMISHING))]\n",
    "\n",
    "# Let's check if they are gone\n",
    "print('spam messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SPAM].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages2vectors(messages):\n",
    "    '''\n",
    "    Transforms single message into feature-vector;\n",
    "    Parameters:\n",
    "        messages    -   array of strings;\n",
    "    Returns:\n",
    "        features    -   array of feature-vectors;   \n",
    "    '''\n",
    "\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\")\n",
    "\n",
    "    features = np.zeros((0, 1024))\n",
    "    n = 100\n",
    "    l = int(len(messages) / n) if len(messages) % n == 0 else int(len(messages) / n) + 1\n",
    "    for i in range(l):\n",
    "\n",
    "        if (i + 1) * n < len(messages):\n",
    "            right = (i + 1) * n\n",
    "            embedds = elmo(messages[int(i * n) : right], signature=\"default\", as_dict=True)[\"default\"] \n",
    "        else:\n",
    "            embedds = elmo(messages[:len(messages) - int(i * n)], signature=\"default\", as_dict=True)[\"default\"] \n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            embedds = sess.run(embedds)\n",
    "            features = np.concatenate([features, embedds])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(labels_raw):\n",
    "\n",
    "    # add your code here\n",
    "    labels = np.zeros(len(labels_raw), 'int')\n",
    "    for i in range(len(labels_raw)):\n",
    "        if labels_raw[i] == 'SMIS':\n",
    "            labels[i] = 1\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "(1427, 1024)\n",
      "(1427,)\n"
     ]
    }
   ],
   "source": [
    "features = messages2vectors(dataset[COLUMN_TEXT])\n",
    "labels = convert_labels(dataset[COLUMN_LABEL])\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features, labels, ratio=0.7):\n",
    "    '''\n",
    "    Splits dataset into train/test parts using given ratio;\n",
    "    Parameters:\n",
    "        data    -   array of features;\n",
    "        labels  -   array of corresponding labels;\n",
    "        ratio   -   train/test size ratio;\n",
    "    Returns:\n",
    "        train_data      -   array of training features;   \n",
    "        train_labels    -   array of training labels; \n",
    "        test_data       -   array of testing features; \n",
    "        test_labels     -   array of testing labels; \n",
    "    '''    \n",
    "\n",
    "\n",
    "    positive_data = features[labels == 1] # all smish features\n",
    "    negative_data = features[labels == 0] # all legit features\n",
    "\n",
    "    # We shuffle arrays to get random samples later\n",
    "    random_indecies_positive = np.arange(positive_data.shape[0])\n",
    "    np.random.shuffle(random_indecies_positive)\n",
    "    random_indecies_negative = np.arange(negative_data.shape[0])\n",
    "    np.random.shuffle(random_indecies_negative)\n",
    "\n",
    "    n_positive_train = int(positive_data.shape[0] * ratio)\n",
    "    n_negative_train = int(negative_data.shape[0] * ratio)\n",
    "\n",
    "    # Training data are all indecies in 'ratio' part of shuffled indecies\n",
    "    train_data = np.concatenate([positive_data[random_indecies_positive[:n_positive_train]], \n",
    "                                negative_data[random_indecies_negative[:n_negative_train]]])\n",
    "    \n",
    "    train_labels = np.asarray([1] * n_positive_train + [0] * n_negative_train)\n",
    "\n",
    "    # Testing data are all indecies that remain\n",
    "    test_data = np.concatenate([positive_data[random_indecies_positive[n_positive_train:]], \n",
    "                                negative_data[random_indecies_negative[n_negative_train:]]])\n",
    "\n",
    "    test_labels = np.asarray([1] * (positive_data.shape[0]  - n_positive_train) + [0] * (negative_data.shape[0] - n_negative_train))\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(labels, predictions):\n",
    "    '''\n",
    "    Computes metrics;\n",
    "    Parameters:\n",
    "        labels    -   array of labels;\n",
    "        predictions  -   array of predictions;\n",
    "    Returns:\n",
    "        FAR -   False Acceptance Rate;\n",
    "        FRR -   False Rejection Rate;\n",
    "    '''  \n",
    "    # add your code here\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    FAR = fp / (fp + tn) * 100\n",
    "    FRR = fn / (tp + fn) * 100\n",
    "    return FAR, FRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(classifierType, hyperparameters, features, labels):\n",
    "\n",
    "    '''\n",
    "    Splits dataset into train/test parts using given ratio;\n",
    "    Parameters:\n",
    "        classifierType      -   type of ML algorithm to use;\n",
    "        hyperparameters     -   dictionary of model's parameters;\n",
    "        features            -   array of features;\n",
    "        labels              -   array of labels\n",
    "    Returns:\n",
    "        trainFAR    -   False Acceptance Rate for train dataset;\n",
    "        trainFRR    -   False Rejection Rate for train dataset;\n",
    "        testFAR     -   False Acceptance Rate for test dataset;\n",
    "        testFRR    -   False Rejection Rate for test dataset;\n",
    "    '''    \n",
    "\n",
    "    model = GridSearchCV(classifierType(), hyperparameters, n_jobs = -1, refit = 'precision_score')\n",
    "\n",
    "    # Split data\n",
    "    train_data, train_labels, test_data, test_labels = split_data(features, labels, ratio=0.7) \n",
    "\n",
    "    # Fit your model\n",
    "    # add your code here\n",
    "    fitted_model = model.fit(train_data, train_labels)\n",
    "    # Make predictions for training dataset\n",
    "    # add your code here\n",
    "    predict_train = fitted_model.predict(train_data)\n",
    "\n",
    "    # Compute train FAR/FRR\n",
    "    # add your code here\n",
    "    trainFAR, trainFRR = get_metrics(train_labels, predict_train)\n",
    "\n",
    "    # Make predictions for testing dataset\n",
    "    # add your code here\n",
    "    predictions_test = fitted_model.predict(test_data)  \n",
    "    # Compute test FAR/FRR\n",
    "    # add your code here\n",
    "    testFAR, testFRR = get_metrics(test_labels, predictions_test)\n",
    "    print('\\tThe best parametrs are', fitted_model.best_params_)\n",
    "    return trainFAR, trainFRR, testFAR, testFRR"
   ]
  },
  {
   "source": [
    "First algorithm - RandomForest\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierType = sklearn.ensemble.RandomForestClassifier\n",
    "hyperparameters = {'n_estimators' : list(range(80, 150, 10)),\n",
    "                'criterion' : ['gini'],\n",
    "                'max_depth' : [None],\n",
    "                'min_samples_split' : [2],\n",
    "                'min_samples_leaf' : [2]}"
   ]
  },
  {
   "source": [
    "Сначала проверяла по большему разбросу, в итоге сошлаось к таким вариантам как выше  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tThe best parametrs are {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 140}\nTrain:\n\tFAR: 0.0\n\tFRR: 0.38022813688212925\nTest:\n\tFAR: 0.31645569620253167\n\tFRR: 24.778761061946902\n"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType, hyperparameters, features, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "source": [
    "Second algorithm - SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierType_2 = sklearn.svm.SVC\n",
    "hyperparameters_2 = { 'C' : [ 10, 30, 40, 100, 500, 1000 ], \n",
    "                'gamma' : [0.00313, 0.003, 0.0031, 0.0032, 0.029, 0.00328, 0.001, 0.01, 0.001], \n",
    "                'kernel' : ['rbf'],\n",
    "                'class_weight' : ['balanced', None]}"
   ]
  },
  {
   "source": [
    "Сначала проверяла по большему разбросу, в итоге сошлаось к таким вариантам как выше  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tThe best parametrs are {'C': 30, 'class_weight': None, 'gamma': 0.01, 'kernel': 'rbf'}\nTrain:\n\tFAR: 0.0\n\tFRR: 0.0\nTest:\n\tFAR: 1.5822784810126582\n\tFRR: 13.274336283185843\n"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType_2, hyperparameters_2, features, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer with multinomial Naive Bayes\n",
    "def train_2(dataset, labels):  \n",
    "    #train test split\n",
    "    train_data, test_data, train_label, test_label = train_test_split(dataset['context'], \n",
    "                                                    labels, \n",
    "                                                    random_state = 1)\n",
    "                                                    \n",
    "    #fitting and transforming train_data using a Count Vectorizer with default parameters\n",
    "    vect = CountVectorizer().fit(train_data)\n",
    "    train_data_vectorized = vect.transform(train_data)\n",
    "    #fitting a multinomial Naive Bayes Classifier Model with smoothing alpha=0.1\n",
    "    model = sklearn.naive_bayes.MultinomialNB(alpha=0.1)\n",
    "    model_fit = model.fit(train_data_vectorized, train_label)\n",
    "    predictions_train = model.predict(vect.transform(train_data))\n",
    "    trainFAR, trainFRR = get_metrics(train_label, predictions_train)\n",
    "    predictions = model.predict(vect.transform(test_data))\n",
    "    testFAR, testFRR = get_metrics(test_label, predictions)\n",
    "    aucscore = roc_auc_score(test_label, predictions)\n",
    "    print(aucscore)\n",
    "    return trainFAR, trainFRR, testFAR, testFRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9600713719270421\nTrain:\n\tFAR: 0.6321112515802781\n\tFRR: 0.7168458781362007\nTest:\n\tFAR: 0.7692307692307693\n\tFRR: 7.216494845360824\n"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = train_2(dataset, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer with multinomial Naive Bayes\n",
    "def train_3(dataset, labels):  \n",
    "    classifierType = sklearn.naive_bayes.MultinomialNB\n",
    "    hyperparameters = {'alpha' : list(range(0.008, 0.2, 0.002))}\n",
    "    #train test split\n",
    "    train_data, test_data, train_label, test_label = train_test_split(dataset['context'], \n",
    "                                                    labels, \n",
    "                                                    random_state = 1)\n",
    "                                                    \n",
    "    #fitting and transforming train_data using a Count Vectorizer with default parameters\n",
    "    vect = TfidfVectorizer(min_df = 1).fit(train_data)\n",
    "    train_data_vectorized = vect.transform(train_data)\n",
    "    #fitting a multinomial Naive Bayes Classifier Model with smoothing alpha=0.1\n",
    "    model = GridSearchCV(classifierType(), hyperparameters, n_jobs = -1, refit = 'precision_score')\n",
    "    model_fit = model.fit(train_data_vectorized, train_label)\n",
    "    predictions_train = model.predict(vect.transform(train_data))\n",
    "    trainFAR, trainFRR = get_metrics(train_label, predictions_train)\n",
    "    predictions = model.predict(vect.transform(test_data))\n",
    "    testFAR, testFRR = get_metrics(test_label, predictions)\n",
    "    aucscore = roc_auc_score(test_label, predictions)\n",
    "    print(aucscore)\n",
    "    print('\\tThe best parametrs are', model_fit.best_params_)\n",
    "    return trainFAR, trainFRR, testFAR, testFRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-de714c1f03b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainFAR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainFRR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestFAR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestFRR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\tFAR:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainFAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\tFRR:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainFRR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-134-93a72d4165f6>\u001b[0m in \u001b[0;36mtrain_3\u001b[1;34m(dataset, labels)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mclassifierType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mhyperparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'alpha'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.008\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.002\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#train test split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     train_data, test_data, train_label, test_label = train_test_split(dataset['context'], \n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = train_3(dataset, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer with RandomForestClassifier\n",
    "def train_4(dataset, labels):  \n",
    "    classifierType = sklearn.ensemble.RandomForestClassifier\n",
    "    hyperparameters = {'n_estimators' : list(range(50, 200, 10)),\n",
    "                'criterion' : ['gini'],\n",
    "                'max_depth' : [None],\n",
    "                'min_samples_split' : [2, 3, 4],\n",
    "                'min_samples_leaf' : [2, 4, 3]}\n",
    "    #train test split\n",
    "    train_data, test_data, train_label, test_label = train_test_split(dataset['context'], \n",
    "                                                    labels, \n",
    "                                                    random_state = 1)\n",
    "                                                    \n",
    "    #fitting and transforming train_data using a Count Vectorizer with default parameters\n",
    "    vect = CountVectorizer().fit(train_data)\n",
    "    train_data_vectorized = vect.transform(train_data)\n",
    "    model = GridSearchCV(classifierType(), hyperparameters, n_jobs = -1, refit = 'precision_score')\n",
    "    model_fit = model.fit(train_data_vectorized, train_label)\n",
    "    predictions_train = model.predict(vect.transform(train_data))\n",
    "    trainFAR, trainFRR = get_metrics(train_label, predictions_train)\n",
    "    predictions = model.predict(vect.transform(test_data))\n",
    "    testFAR, testFRR = get_metrics(test_label, predictions)\n",
    "    aucscore = roc_auc_score(test_label, predictions)\n",
    "    print(aucscore)\n",
    "    \n",
    "    print('\\tThe best parametrs are', model_fit.best_params_)\n",
    "    return trainFAR, trainFRR, testFAR, testFRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8195876288659794\n\tThe best parametrs are {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\nTrain:\n\tFAR: 0.0\n\tFRR: 11.469534050179211\nTest:\n\tFAR: 0.0\n\tFRR: 36.08247422680412\n"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = train_4(dataset, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer with SVC\n",
    "def train_5(dataset, labels):  \n",
    "    classifierType = sklearn.svm.SVC\n",
    "    hyperparameters_2 = { 'C' : [ 10, 30, 40, 100, 500, 1000 ], \n",
    "                'gamma' : [0.00313, 0.003, 0.0031, 0.0032, 0.029, 0.00328, 0.001, 0.01, 0.001], \n",
    "                'kernel' : ['rbf'],\n",
    "                'class_weight' : ['balanced', None]}\n",
    "    #train test split\n",
    "    train_data, test_data, train_label, test_label = train_test_split(dataset['context'], \n",
    "                                                    labels, \n",
    "                                                    random_state = 1)\n",
    "                                                    \n",
    "    #fitting and transforming train_data using a Count Vectorizer with default parameters\n",
    "    vect = CountVectorizer().fit(train_data)\n",
    "    train_data_vectorized = vect.transform(train_data)\n",
    "    model = GridSearchCV(classifierType(), hyperparameters_2, n_jobs = -1, refit = 'precision_score')\n",
    "    model_fit = model.fit(train_data_vectorized, train_label)\n",
    "    predictions_train = model.predict(vect.transform(train_data))\n",
    "    trainFAR, trainFRR = get_metrics(train_label, predictions_train)\n",
    "    predictions = model.predict(vect.transform(test_data))\n",
    "    testFAR, testFRR = get_metrics(test_label, predictions)\n",
    "    aucscore = roc_auc_score(test_label, predictions)\n",
    "    print(aucscore)\n",
    "    \n",
    "    print('\\tThe best parametrs are', model_fit.best_params_)\n",
    "    return trainFAR, trainFRR, testFAR, testFRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9465305313243457\n\tThe best parametrs are {'C': 10, 'class_weight': None, 'gamma': 0.01, 'kernel': 'rbf'}\nTrain:\n\tFAR: 0.0\n\tFRR: 0.7168458781362007\nTest:\n\tFAR: 0.38461538461538464\n\tFRR: 10.309278350515463\n"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = train_5(dataset, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer with SVC\n",
    "def train_6(dataset, labels):  \n",
    "    classifierType = sklearn.svm.SVC\n",
    "    hyperparameters_2 = { 'C' : [ 10, 30, 40, 100, 500, 1000 ], \n",
    "                'gamma' : [0.00313, 0.003, 0.0031, 0.0032, 0.029, 0.00328, 0.001, 0.01, 0.001], \n",
    "                'kernel' : ['rbf'],\n",
    "                'class_weight' : ['balanced', None]}\n",
    "    #train test split\n",
    "    train_data, test_data, train_label, test_label = train_test_split(dataset['context'], \n",
    "                                                    labels, \n",
    "                                                    random_state = 1)\n",
    "                                                    \n",
    "    #fitting and transforming train_data using a Count Vectorizer with default parameters\n",
    "    vect = TfidfVectorizer(min_df = 1).fit(train_data)\n",
    "    train_data_vectorized = vect.transform(train_data)\n",
    "    model = GridSearchCV(classifierType(), hyperparameters_2, n_jobs = -1, refit = 'precision_score')\n",
    "    model_fit = model.fit(train_data_vectorized, train_label)\n",
    "    predictions_train = model.predict(vect.transform(train_data))\n",
    "    trainFAR, trainFRR = get_metrics(train_label, predictions_train)\n",
    "    predictions = model.predict(vect.transform(test_data))\n",
    "    testFAR, testFRR = get_metrics(test_label, predictions)\n",
    "    aucscore = roc_auc_score(test_label, predictions)\n",
    "    print(aucscore)\n",
    "    \n",
    "    print('\\tThe best parametrs are', model_fit.best_params_)\n",
    "    return trainFAR, trainFRR, testFAR, testFRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9703806502775575\n\tThe best parametrs are {'C': 1000, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\nTrain:\n\tFAR: 0.0\n\tFRR: 0.0\nTest:\n\tFAR: 0.7692307692307693\n\tFRR: 5.154639175257731\n"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = train_6(dataset, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer with RandomForestClassifier\n",
    "def train_7(dataset, labels):  \n",
    "    classifierType = sklearn.ensemble.RandomForestClassifier\n",
    "    hyperparameters = {'n_estimators' : list(range(50, 200, 10)),\n",
    "                'criterion' : ['gini'],\n",
    "                'max_depth' : [None],\n",
    "                'min_samples_split' : [2, 3, 4],\n",
    "                'min_samples_leaf' : [2, 4, 3]}\n",
    "    #train test split\n",
    "    train_data, test_data, train_label, test_label = train_test_split(dataset['context'], \n",
    "                                                    labels, \n",
    "                                                    random_state = 1)\n",
    "                                                    \n",
    "    #fitting and transforming train_data using a Count Vectorizer with default parameters\n",
    "    vect = TfidfVectorizer(min_df = 1).fit(train_data)\n",
    "    train_data_vectorized = vect.transform(train_data)\n",
    "    model = GridSearchCV(classifierType(), hyperparameters, n_jobs = -1, refit = 'precision_score')\n",
    "    model_fit = model.fit(train_data_vectorized, train_label)\n",
    "    predictions_train = model.predict(vect.transform(train_data))\n",
    "    trainFAR, trainFRR = get_metrics(train_label, predictions_train)\n",
    "    predictions = model.predict(vect.transform(test_data))\n",
    "    testFAR, testFRR = get_metrics(test_label, predictions)\n",
    "    aucscore = roc_auc_score(test_label, predictions)\n",
    "    print(aucscore)\n",
    "    print('\\tThe best parametrs are', model_fit.best_params_)\n",
    "    return trainFAR, trainFRR, testFAR, testFRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8195876288659794\n\tThe best parametrs are {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100}\nTrain:\n\tFAR: 0.0\n\tFRR: 8.960573476702509\nTest:\n\tFAR: 0.0\n\tFRR: 36.08247422680412\n"
     ]
    }
   ],
   "source": [
    "trainFAR, trainFRR, testFAR, testFRR = train_7(dataset, labels)\n",
    "print('Train:')\n",
    "print('\\tFAR:', trainFAR)\n",
    "print('\\tFRR:', trainFRR)\n",
    "\n",
    "print('Test:')\n",
    "print('\\tFAR:', testFAR)\n",
    "print('\\tFRR:', testFRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}