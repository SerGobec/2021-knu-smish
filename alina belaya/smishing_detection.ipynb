{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smishing_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmbQ-gy7xzyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca450210-ff46-410f-9983-a50b378ebe27"
      },
      "source": [
        "import tensorflow_hub as hub\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "tf.disable_eager_execution()\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import sklearn\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTBRhRD85LrF"
      },
      "source": [
        "# specify location your dataset here\r\n",
        "DATA_PATH = \"SMS_dataset_preparation.txt\"\r\n",
        "\r\n",
        "# give name to label-column and text-column\r\n",
        "COLUMN_LABEL = \"lable\"\r\n",
        "COLUMN_TEXT = \"text\"\r\n",
        "\r\n",
        "# these are labels that indicate the type of message.\r\n",
        "LABEL_LEGIT = 'LEGI'\r\n",
        "LABEL_SPAM = 'SPAM'\r\n",
        "LABEL_SMISHING = 'SMIS'"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7ZJOEwpyPh3",
        "outputId": "fe8b7df5-303c-452b-b7e0-235327b182dd"
      },
      "source": [
        "dataset = pd.read_csv(DATA_PATH, sep='\\t', names=[COLUMN_LABEL, COLUMN_TEXT], header=None)\r\n",
        "print('Total size:', dataset.shape[0])\r\n",
        "print('Legit messages:', dataset[dataset[COLUMN_LABEL] == LABEL_LEGIT].shape[0])\r\n",
        "print('Spam messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SPAM].shape[0])\r\n",
        "print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total size: 1509\n",
            "Legit messages: 1060\n",
            "Spam messages: 163\n",
            "Smishing messages: 286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efLnzc38yjLm"
      },
      "source": [
        "def find_url(message):\r\n",
        "  r = re.compile(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\")\r\n",
        "  url = r.findall(message)\r\n",
        "  return [i[0] for i in url]"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCD2QGkFf127"
      },
      "source": [
        "def find_numb(message):\r\n",
        "  r = re.compile(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})')\r\n",
        "  numb = r.findall(message)\r\n",
        "  return numb"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ-KVYhFgDjR"
      },
      "source": [
        "def find_email(message):\r\n",
        "  r = re.compile(r'(\\b[\\w.]+@+[\\w.]+.+[\\w.]\\b)')\r\n",
        "  email = r.findall(message)\r\n",
        "  return email"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0MJMsuXyoHm"
      },
      "source": [
        "def messages2vectors(messages, size):\r\n",
        "  '''\r\n",
        "    Transforms single message into feature-vector;\r\n",
        "    Parameters:\r\n",
        "        messages    -   array of strings;\r\n",
        "    Returns:\r\n",
        "        features    -   array of feature-vectors;   \r\n",
        "    '''\r\n",
        "\r\n",
        "  features = np.zeros((size, 10))\r\n",
        "  count = 0\r\n",
        "\r\n",
        "  greet_key = ['good morn', 'good afternoon', 'good even', 'good night',\r\n",
        "               'hi', 'hello', 'hey',\r\n",
        "               'gud nyt', 'good ni8', 'good nyt', 'goodnight']\r\n",
        "\r\n",
        "  emotion_key = ['love', 'nice', 'sweet', 'happi',\r\n",
        "                 'sad', 'angri', 'hurt', 'nasti', ':)', ':(']\r\n",
        "  \r\n",
        "  mat_symb = ['|', '{', '@', '[', '<', '!', '+', '(', '$', '/', '%', '^']\r\n",
        "\r\n",
        "  sal = ['call', 'claim', 'reciev', 'click', 'enter',\r\n",
        "         'visit', 'repli', 'send', 'contact', 'appli',\r\n",
        "         'follow', 'subscrib', 'unsubscrib', 'answer']\r\n",
        "\r\n",
        "  money_symb = ['UAH', '£', '$', '€']\r\n",
        "\r\n",
        "  smis_key = ['award', 'congratul', 'winner', 'alert', 'claim',\r\n",
        "              'activat', 'verifi', 'attempts', 'gift', 'voucher',\r\n",
        "              'block', 'suspend', 'unlock', 'won', 'prize',\r\n",
        "              'subscrib', 'activ', 'updat', 'coupon', 'refund']\r\n",
        "\r\n",
        "  for f in features:\r\n",
        "    #print('\\nMessage: ', messages[count])\r\n",
        "    f[0] = 1\r\n",
        "    f[1] = 1\r\n",
        "\r\n",
        "    for key in greet_key:\r\n",
        "      if key in messages[count]:\r\n",
        "        #print('greet: ', key)\r\n",
        "        f[0] = 0\r\n",
        "    \r\n",
        "    for key in emotion_key:\r\n",
        "      if key in messages[count]:\r\n",
        "        #print('emotion: ', key)\r\n",
        "        f[1] = 0\r\n",
        "    \r\n",
        "    url = find_url(messages[count])\r\n",
        "    if url != []:\r\n",
        "      f[2] = 1\r\n",
        "    \r\n",
        "    for symb in mat_symb:\r\n",
        "      if symb in messages[count]:\r\n",
        "        f[3] = 1\r\n",
        "    \r\n",
        "    if len(messages[count]) >= 150:\r\n",
        "      f[4] = 1\r\n",
        "\r\n",
        "    for sign in sal:\r\n",
        "      if sign in messages[count]:\r\n",
        "        #print('sal: ', sign)\r\n",
        "        f[5] = 1\r\n",
        "\r\n",
        "    for symb in money_symb:\r\n",
        "      if symb in messages[count]:\r\n",
        "        f[6] = 1\r\n",
        "      \r\n",
        "    for sign in smis_key:\r\n",
        "      if sign in messages[count]:\r\n",
        "        #print('smis: ', sign)\r\n",
        "        f[7] = 1\r\n",
        "    \r\n",
        "    email = find_email(messages[count])\r\n",
        "    if email != []:\r\n",
        "      f[8] = 1\r\n",
        "\r\n",
        "    number = find_numb(messages[count])\r\n",
        "    if number != []:\r\n",
        "      f[9] = 1\r\n",
        "    \r\n",
        "    count += 1\r\n",
        "  return features"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JltX7XFhYXa"
      },
      "source": [
        "def convert_messages(messages):\r\n",
        "    ps = PorterStemmer()\r\n",
        "    dataset = []\r\n",
        "    for message in messages:\r\n",
        "      #print('message: ', message)\r\n",
        "      new_message = message.lower()\r\n",
        "      url = find_url(new_message)\r\n",
        "      if url != []:\r\n",
        "        #print('url: ', url[0])\r\n",
        "        new_message = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\", '', new_message, flags=re.MULTILINE)\r\n",
        "      new_message_split = word_tokenize(new_message)\r\n",
        "      sms_stem = [ps.stem(word) for word in new_message_split]\r\n",
        "      sms = ' '.join(sms_stem)\r\n",
        "      if url != []:\r\n",
        "        sms += ' ' + url[0]\r\n",
        "      dataset.append(sms)\r\n",
        "    return dataset"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP4xHCiRythN"
      },
      "source": [
        "def convert_labels(labels_raw):\r\n",
        "    '''\r\n",
        "    Transforms labels into numerical values;\r\n",
        "    Parameters:\r\n",
        "        labels_raw    -   array of text-labels;\r\n",
        "    Returns:\r\n",
        "        features    -   array of numerical labels;\r\n",
        "    '''\r\n",
        "\r\n",
        "    label = []\r\n",
        "    for lab in labels_raw:\r\n",
        "        if lab == 'LEGI' or lab == 'SPAM':\r\n",
        "            label.append(0)\r\n",
        "        elif lab == 'SMIS':\r\n",
        "            label.append(1)\r\n",
        "    labels = np.array(label)\r\n",
        "\r\n",
        "    return labels\r\n"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSTELQwZ57RA",
        "outputId": "dc790ce7-2e21-47cb-9b9c-1ebf0ba9cdc1"
      },
      "source": [
        "dataset_steem = convert_messages(dataset[COLUMN_TEXT])\r\n",
        "features = messages2vectors(dataset_steem, dataset.shape[0])\r\n",
        "labels = convert_labels(dataset[COLUMN_LABEL])\r\n",
        "print(features.shape)\r\n",
        "print(labels.shape)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1509, 10)\n",
            "(1509,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbZQkDkMV2Ve"
      },
      "source": [
        "def split_data(features, labels, ratio=0.7):\r\n",
        "    '''\r\n",
        "    Splits dataset into train/test parts using given ratio;\r\n",
        "    Parameters:\r\n",
        "        data    -   array of features;\r\n",
        "        labels  -   array of corresponding labels;\r\n",
        "        ratio   -   train/test size ratio;\r\n",
        "    Returns:\r\n",
        "        train_data      -   array of training features;   \r\n",
        "        train_labels    -   array of training labels; \r\n",
        "        test_data       -   array of testing features; \r\n",
        "        test_labels     -   array of testing labels; \r\n",
        "    '''    \r\n",
        "\r\n",
        "\r\n",
        "    positive_data = features[labels == 1] # all spam features\r\n",
        "    negative_data = features[labels == 0] # all legit features\r\n",
        "\r\n",
        "    # We shuffle arrays to get random samples later\r\n",
        "    random_indecies_positive = np.arange(positive_data.shape[0])\r\n",
        "    np.random.shuffle(random_indecies_positive)\r\n",
        "    random_indecies_negative = np.arange(negative_data.shape[0])\r\n",
        "    np.random.shuffle(random_indecies_negative)\r\n",
        "\r\n",
        "    n_positive_train = int(positive_data.shape[0] * ratio)\r\n",
        "    n_negative_train = int(negative_data.shape[0] * ratio)\r\n",
        "\r\n",
        "    # Training data are all indecies in 'ratio' part of shuffled indecies\r\n",
        "    train_data = np.concatenate([positive_data[random_indecies_positive[:n_positive_train]], \r\n",
        "                                negative_data[random_indecies_negative[:n_negative_train]]])\r\n",
        "    \r\n",
        "    train_labels = np.asarray([1] * n_positive_train + [0] * n_negative_train)\r\n",
        "\r\n",
        "    # Testing data are all indecies that remain\r\n",
        "    test_data = np.concatenate([positive_data[random_indecies_positive[n_positive_train:]], \r\n",
        "                                negative_data[random_indecies_negative[n_negative_train:]]])\r\n",
        "\r\n",
        "    test_labels = np.asarray([1] * (positive_data.shape[0]  - n_positive_train) + [0] * (negative_data.shape[0] - n_negative_train))\r\n",
        "\r\n",
        "    return train_data, train_labels, test_data, test_labels"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp8o_BsaV8Sq"
      },
      "source": [
        "def get_metrics(labels, predictions):\r\n",
        "    '''\r\n",
        "    Computes metrics;\r\n",
        "    Parameters:\r\n",
        "        labels    -   array of labels;\r\n",
        "        predictions  -   array of predictions;\r\n",
        "    Returns:\r\n",
        "        FAR -   False Acceptance Rate;\r\n",
        "        FRR -   False Rejection Rate;\r\n",
        "    '''  \r\n",
        "    TN, FP, FN, TP = confusion_matrix(labels, predictions).ravel()\r\n",
        "    FAR = FP/(FP + TN)\r\n",
        "    FRR = FN/(FN + TP)\r\n",
        "    return FAR*100, FRR*100"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaKBPLG4V_yw"
      },
      "source": [
        "def evaluate(classifierType, hyperparameters, features, labels):\r\n",
        "    '''\r\n",
        "    Splits dataset into train/test parts using given ratio;\r\n",
        "    Parameters:\r\n",
        "        classifierType      -   type of ML algorithm to use;\r\n",
        "        hyperparameters     -   dictionary of model's parameters;\r\n",
        "        features            -   array of features;\r\n",
        "        labels              -   array of labels\r\n",
        "    Returns:\r\n",
        "        trainFAR    -   False Acceptance Rate for train dataset;\r\n",
        "        trainFRR    -   False Rejection Rate for train dataset;\r\n",
        "        testFAR     -   False Acceptance Rate for test dataset;\r\n",
        "        testFRR    -   False Rejection Rate for test dataset;\r\n",
        "    '''    \r\n",
        "\r\n",
        "    model = classifierType(**hyperparameters)\r\n",
        "\r\n",
        "    # Split data\r\n",
        "    train_data, train_labels, test_data, test_labels = split_data(features, labels)\r\n",
        "\r\n",
        "    #print('Train set shape:', train_data.shape)\r\n",
        "    #print('Train labels shape:', train_labels.shape)\r\n",
        "    #print('Test set shape:', test_data.shape)\r\n",
        "    #print('Test labels shape:', test_labels.shape)\r\n",
        "\r\n",
        "    # Fit your model\r\n",
        "    fit_model = model.fit(train_data, train_labels)\r\n",
        "\r\n",
        "\r\n",
        "    # Make predictions for training dataset\r\n",
        "    predictions_train =     fit_model.predict(train_data)\r\n",
        "\r\n",
        "\r\n",
        "    # Compute train FAR/FRR\r\n",
        "    trainFAR, trainFRR = get_metrics(train_labels, predictions_train)\r\n",
        "\r\n",
        "    # Make predictions for testing dataset\r\n",
        "    predictions_test = fit_model.predict(test_data)\r\n",
        "\r\n",
        "    # Compute test FAR/FRR\r\n",
        "    testFAR, testFRR = get_metrics(test_labels, predictions_test)\r\n",
        "\r\n",
        "    return trainFAR, trainFRR, testFAR, testFRR"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QNb1SXEXWTN"
      },
      "source": [
        "classifierType1 = sklearn.ensemble.RandomForestClassifier\r\n",
        "hyperparameters1 = {'n_estimators' : 100,\r\n",
        "                'criterion' : 'gini',\r\n",
        "                'max_depth' : None,\r\n",
        "                'min_samples_split' : 2}"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oymt3x0AXY0R",
        "outputId": "6bf7e52a-a1c3-4568-e8d2-30996ff11f94"
      },
      "source": [
        "# Check if it works :)\r\n",
        "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType1, hyperparameters1, features, labels)\r\n",
        "print(\"\\tRandom Forest\")\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tRandom Forest\n",
            "Train:\n",
            "\tFAR: 3.2710280373831773\n",
            "\tFRR: 8.5\n",
            "Test:\n",
            "\tFAR: 5.177111716621254\n",
            "\tFRR: 18.6046511627907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_SnVDdQWNvl"
      },
      "source": [
        "classifierType2 = sklearn.svm.SVC\r\n",
        "hyperparameters2 = {'C': 1.0,\r\n",
        "                   'kernel': 'rbf',\r\n",
        "                   'degree': 0.03,\r\n",
        "                   'gamma': 'scale'}"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2qxM6R-X1yh",
        "outputId": "1f1c70f4-a5b7-4d49-8cc7-93bef49033af"
      },
      "source": [
        "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType2, hyperparameters2, features, labels)\r\n",
        "print('\\tSVM')\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tSVM\n",
            "Train:\n",
            "\tFAR: 3.9719626168224296\n",
            "\tFRR: 17.0\n",
            "Test:\n",
            "\tFAR: 4.904632152588556\n",
            "\tFRR: 11.627906976744185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgcSsXPwWSMO"
      },
      "source": [
        "classifierType3 = sklearn.neighbors.KNeighborsClassifier\r\n",
        "hyperparameters3 = {'n_neighbors': 5,\r\n",
        "                   'weights': 'uniform',\r\n",
        "                   'algorithm': 'auto',\r\n",
        "                   'leaf_size': 30, \r\n",
        "                   'p': 2}"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp_H3qkjYdAx",
        "outputId": "6d791534-9306-4b1e-e035-88bb0e4b5f6e"
      },
      "source": [
        "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType3, hyperparameters3, features, labels)\r\n",
        "print('\\tK Neighbors')\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tK Neighbors\n",
            "Train:\n",
            "\tFAR: 7.009345794392523\n",
            "\tFRR: 8.0\n",
            "Test:\n",
            "\tFAR: 7.3569482288828345\n",
            "\tFRR: 15.11627906976744\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}