{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.7.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "my_spam_detection_guide.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKSpEX_O3Rnw"
      },
      "source": [
        "# SPAM DETECTION GUIDE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4iSs2e3RoK"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fNc4LZeI3Ro-"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OrPXYRsb3RpB"
      },
      "source": [
        "# specify location your dataset here\n",
        "DATA_PATH = \"SMS_dataset_preparation.txt\"\n",
        "\n",
        "# give name to label-column and text-column\n",
        "COLUMN_LABEL = \"lable\"\n",
        "COLUMN_TEXT = \"text\"\n",
        "\n",
        "# these are labels that indicate the type of message.\n",
        "LABEL_LEGIT = 'LEGI'\n",
        "LABEL_SPAM = 'SPAM'\n",
        "LABEL_SMISHING = 'SMIS'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ihva4UB3RpC"
      },
      "source": [
        "## Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD4JHBbA3RpD",
        "outputId": "3d8ecea0-8e5f-4964-f69c-b540f0d78984"
      },
      "source": [
        "dataset = pd.read_csv(DATA_PATH, sep='\\t', names=[COLUMN_LABEL, COLUMN_TEXT], header=None)\n",
        "print('Total size:', dataset.shape[0])\n",
        "print('Legit messages:', dataset[dataset[COLUMN_LABEL] == LABEL_LEGIT].shape[0])\n",
        "print('Spam messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SPAM].shape[0])\n",
        "print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total size: 1509\n",
            "Legit messages: 1060\n",
            "Spam messages: 163\n",
            "Smishing messages: 286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8dZqgr3RpG",
        "outputId": "40173a84-e924-4dbe-e203-8c02193a9915"
      },
      "source": [
        "dataset = dataset[((dataset[COLUMN_LABEL] == LABEL_LEGIT) | (dataset[COLUMN_LABEL] == LABEL_SPAM))]\n",
        "\n",
        "# Let's check if they are gone\n",
        "print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smishing messages: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TVh8ZHE3RpJ"
      },
      "source": [
        "## Data preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "W79fNnw73RpN"
      },
      "source": [
        "def messages2vectors(messages):\n",
        "    '''\n",
        "    Transforms single message into feature-vector;\n",
        "    Parameters:\n",
        "        messages    -   array of strings;\n",
        "    Returns:\n",
        "        features    -   array of feature-vectors;   \n",
        "    '''\n",
        "\n",
        "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\")\n",
        "\n",
        "    features = np.zeros((0, 1024))\n",
        "    n = 100\n",
        "    l = int(len(messages) / n) + 1 if len(messages) % 2 != 0 else int(len(messages) / n)\n",
        "    for i in range(l):\n",
        "        if i * n == len(messages):\n",
        "            break\n",
        "        if (i + 1) * n < len(messages):\n",
        "            right = (i + 1) * n\n",
        "            embedds = elmo(messages[int(i * n) : right], signature=\"default\", as_dict=True)[\"default\"] \n",
        "        else:\n",
        "            embedds = elmo(messages[:len(messages) - int(i * n)], signature=\"default\", as_dict=True)[\"default\"] \n",
        "\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            embedds = sess.run(embedds)\n",
        "            features = np.concatenate([features, embedds])\n",
        "\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D6_BWPvE3RpQ"
      },
      "source": [
        "def convert_labels(labels_raw):\n",
        "    '''\n",
        "    Transforms labels into numerical values;\n",
        "    Parameters:\n",
        "        labels_raw    -   array of text-labels;\n",
        "    Returns:\n",
        "        features    -   array of numerical labels;   \n",
        "    ''' \n",
        "\n",
        "    label = []\n",
        "    for lab in labels_raw:\n",
        "        if lab == 'LEGI':\n",
        "            label.append(0)\n",
        "        elif lab == 'SPAM':\n",
        "            label.append(1)\n",
        "    labels = np.array(label)\n",
        "\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n13EyoAA3RpS",
        "outputId": "6aec94a2-0600-410a-e7ee-cd98654fe4e9"
      },
      "source": [
        "features = messages2vectors(dataset[COLUMN_TEXT])\n",
        "labels = convert_labels(dataset[COLUMN_LABEL])\n",
        "print(features.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1223, 1024)\n",
            "(1223,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOPt9PMJ3RpX"
      },
      "source": [
        "def split_data(features, labels, ratio=0.7):\n",
        "    '''\n",
        "    Splits dataset into train/test parts using given ratio;\n",
        "    Parameters:\n",
        "        data    -   array of features;\n",
        "        labels  -   array of corresponding labels;\n",
        "        ratio   -   train/test size ratio;\n",
        "    Returns:\n",
        "        train_data      -   array of training features;   \n",
        "        train_labels    -   array of training labels; \n",
        "        test_data       -   array of testing features; \n",
        "        test_labels     -   array of testing labels; \n",
        "    '''    \n",
        "\n",
        "\n",
        "    positive_data = features[labels == 1] # all spam features\n",
        "    negative_data = features[labels == 0] # all legit features\n",
        "\n",
        "    # We shuffle arrays to get random samples later\n",
        "    random_indecies_positive = np.arange(positive_data.shape[0])\n",
        "    np.random.shuffle(random_indecies_positive)\n",
        "    random_indecies_negative = np.arange(negative_data.shape[0])\n",
        "    np.random.shuffle(random_indecies_negative)\n",
        "\n",
        "    n_positive_train = int(positive_data.shape[0] * ratio)\n",
        "    n_negative_train = int(negative_data.shape[0] * ratio)\n",
        "\n",
        "    # Training data are all indecies in 'ratio' part of shuffled indecies\n",
        "    train_data = np.concatenate([positive_data[random_indecies_positive[:n_positive_train]], \n",
        "                                negative_data[random_indecies_negative[:n_negative_train]]])\n",
        "    \n",
        "    train_labels = np.asarray([1] * n_positive_train + [0] * n_negative_train)\n",
        "\n",
        "    # Testing data are all indecies that remain\n",
        "    test_data = np.concatenate([positive_data[random_indecies_positive[n_positive_train:]], \n",
        "                                negative_data[random_indecies_negative[n_negative_train:]]])\n",
        "\n",
        "    test_labels = np.asarray([1] * (positive_data.shape[0]  - n_positive_train) + [0] * (negative_data.shape[0] - n_negative_train))\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBV0rIOg3Rpb"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PezpFUGzXl4r"
      },
      "source": [
        "def get_confusion_matrix_values(y_true, y_pred):\r\n",
        "    cm = confusion_matrix(y_true, y_pred)\r\n",
        "    return(cm[0][0], cm[0][1], cm[1][0], cm[1][1])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCmhAq3P3Rpe"
      },
      "source": [
        "def get_metrics(labels, predictions):\n",
        "    '''\n",
        "    Computes metrics;\n",
        "    Parameters:\n",
        "        labels    -   array of labels;\n",
        "        predictions  -   array of predictions;\n",
        "    Returns:\n",
        "        FAR -   False Acceptance Rate;\n",
        "        FRR -   False Rejection Rate;\n",
        "    '''  \n",
        "    TN, FP, FN, TP = confusion_matrix(labels, predictions)\n",
        "    FAR = FP/(FP + TN)\n",
        "    FRR = FN/(FN + TP)\n",
        "    return FAR, FRR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr3o44Fo3Rpf"
      },
      "source": [
        "## Model initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlbQmc-e3Rpi"
      },
      "source": [
        "## Model Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw1YQdpG3Rpj"
      },
      "source": [
        "def evaluate(classifierType, hyperparameters, features, labels):\n",
        "    '''\n",
        "    Splits dataset into train/test parts using given ratio;\n",
        "    Parameters:\n",
        "        classifierType      -   type of ML algorithm to use;\n",
        "        hyperparameters     -   dictionary of model's parameters;\n",
        "        features            -   array of features;\n",
        "        labels              -   array of labels\n",
        "    Returns:\n",
        "        trainFAR    -   False Acceptance Rate for train dataset;\n",
        "        trainFRR    -   False Rejection Rate for train dataset;\n",
        "        testFAR     -   False Acceptance Rate for test dataset;\n",
        "        testFRR    -   False Rejection Rate for test dataset;\n",
        "    '''    \n",
        "\n",
        "    model = classifierType(**hyperparameters)\n",
        "\n",
        "    # Split data\n",
        "    train_data, train_labels, test_data, test_labels = split_data(features, labels)\n",
        "\n",
        "    print('Train set shape:', train_data.shape)\n",
        "    print('Train labels shape:', train_labels.shape)\n",
        "    print('Test set shape:', test_data.shape)\n",
        "    print('Test labels shape:', test_labels.shape)\n",
        "\n",
        "    # Fit your model\n",
        "    fit_model = model.fit(train_data, train_labels)\n",
        "\n",
        "\n",
        "    # Make predictions for training dataset\n",
        "    predictions_train =     fit_model.predict(train_data)\n",
        "\n",
        "\n",
        "    # Compute train FAR/FRR\n",
        "    trainFAR, trainFRR = get_metrics(train_labels, predictions_train)\n",
        "\n",
        "    # Make predictions for testing dataset\n",
        "    predictions_test = fit_model.predict(test_data)\n",
        "\n",
        "    # Compute test FAR/FRR\n",
        "    testFAR, testFRR = get_metrics(test_labels, predictions_test)\n",
        "\n",
        "    return trainFAR, trainFRR, testFAR, testFRR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IiW_9xEjpK"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5u7HBua3Rph"
      },
      "source": [
        "classifierType = sklearn.ensemble.RandomForestClassifier\n",
        "hyperparameters = {'n_estimators' : 100,\n",
        "                'criterion' : 'gini',\n",
        "                'max_depth' : None,\n",
        "                'min_samples_split' : 2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHaT4XNL3Rpl",
        "outputId": "7356f302-7313-44ae-9ac1-5a40328286dc"
      },
      "source": [
        "# Check if it works :)\n",
        "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType, hyperparameters, features, labels)\n",
        "print('\\n')\n",
        "print('Train:')\n",
        "print('\\tFAR:', trainFAR)\n",
        "print('\\tFRR:', trainFRR)\n",
        "\n",
        "\n",
        "print('Test:')\n",
        "print('\\tFAR:', testFAR)\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set shape: (856, 1024)\n",
            "Train labels shape: (856,)\n",
            "Test set shape: (367, 1024)\n",
            "Test labels shape: (367,)\n",
            "\n",
            "\n",
            "Train:\n",
            "\tFAR: 0.009523809523809525\n",
            "\tFRR: 0.013315579227696404\n",
            "Test:\n",
            "\tFAR: 0.16216216216216217\n",
            "\tFRR: 0.05454545454545454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kETbSFzV3Rpm"
      },
      "source": [
        "## Final Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP88bJY996Tm"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZU3SEYYl1p7"
      },
      "source": [
        "classifierType = sklearn.svm.SVC\r\n",
        "hyperparameters = {'C': 1.0,\r\n",
        "                   'kernel': 'rbf',\r\n",
        "                   'degree': 0.03,\r\n",
        "                   'gamma': 'scale'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9iu1bHgqOMc",
        "outputId": "69be100d-5fdb-46d5-8a35-67ffe400fe3c"
      },
      "source": [
        "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType, hyperparameters, features, labels)\r\n",
        "print('\\n')\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set shape: (856, 1024)\n",
            "Train labels shape: (856,)\n",
            "Test set shape: (367, 1024)\n",
            "Test labels shape: (367,)\n",
            "\n",
            "\n",
            "Train:\n",
            "\tFAR: 0.011363636363636364\n",
            "\tFRR: 0.03515625\n",
            "Test:\n",
            "\tFAR: 0.10810810810810811\n",
            "\tFRR: 0.048484848484848485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80mJFaTP9CxM"
      },
      "source": [
        "**K Neighbors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1wxuUXf3Rpn"
      },
      "source": [
        "classifierType = sklearn.neighbors.KNeighborsClassifier\n",
        "hyperparameters = {'n_neighbors': 5,\n",
        "                   'weights': 'uniform',\n",
        "                   'algorithm': 'auto',\n",
        "                   'leaf_size': 30, \n",
        "                   'p': 2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRnhjSONf-1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463a6ab2-7e1d-4b8e-e161-4d77893baa79"
      },
      "source": [
        "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType, hyperparameters, features, labels)\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set shape: (856, 1024)\n",
            "Train labels shape: (856,)\n",
            "Test set shape: (367, 1024)\n",
            "Test labels shape: (367,)\n",
            "Train:\n",
            "\tFAR: 0.023529411764705882\n",
            "\tFRR: 0.040207522697795074\n",
            "Test:\n",
            "\tFAR: 0.02857142857142857\n",
            "\tFRR: 0.045180722891566265\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}