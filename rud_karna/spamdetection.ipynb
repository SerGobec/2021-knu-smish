{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spamdetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9aMNg7HHk5E"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# **SPAM DETECTION**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdbC6-VBImjz"
      },
      "source": [
        "important packages and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZQFXmzD-jRS"
      },
      "source": [
        "import tensorflow_hub as hub\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "tf.disable_eager_execution()\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import sklearn\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUeWsQEU_P1Q"
      },
      "source": [
        "# specify location your dataset here\r\n",
        "DATA_PATH = \"data/smsdb.txt\"\r\n",
        "\r\n",
        "# give name to label-column and text-column\r\n",
        "COLUMN_LABEL = \"label\"\r\n",
        "COLUMN_TEXT = \"text\"\r\n",
        "\r\n",
        "# these are labels that indicate the type of message.\r\n",
        "LABEL_LEGIT = 'LEGI'\r\n",
        "LABEL_SPAM = 'SPAM'\r\n",
        "LABEL_SMISHING = 'SMIS'"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJvDurUlPqgG"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0-C88CX_qt2",
        "outputId": "fa96c727-3369-4440-f44f-aafb2a49cd10"
      },
      "source": [
        "dataset = pd.read_csv(DATA_PATH, sep='\\t', names=[COLUMN_LABEL, COLUMN_TEXT], header=None)\r\n",
        "print('Total size:', dataset.shape[0])\r\n",
        "print('Legit messages:', dataset[dataset[COLUMN_LABEL] == LABEL_LEGIT].shape[0])\r\n",
        "print('Spam messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SPAM].shape[0])\r\n",
        "print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total size: 1533\n",
            "Legit messages: 1055\n",
            "Spam messages: 176\n",
            "Smishing messages: 302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYtKZMgzAAfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21c52fc-bbe8-4f40-a6aa-ddc3d2221b39"
      },
      "source": [
        "dataset = dataset[((dataset[COLUMN_LABEL] == LABEL_LEGIT) | (dataset[COLUMN_LABEL] == LABEL_SPAM))]\r\n",
        "\r\n",
        "# Let's check if they are gone\r\n",
        "print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])\r\n",
        "print(len(dataset))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smishing messages: 0\n",
            "1231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dLuHuHtPya1"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c40WQVHjF-YE"
      },
      "source": [
        "def messages2vectors(messages):\r\n",
        "    '''\r\n",
        "    Transforms single message into feature-vector;\r\n",
        "    Parameters:\r\n",
        "        messages    -   array of strings;\r\n",
        "    Returns:\r\n",
        "        features    -   array of feature-vectors;   \r\n",
        "    '''\r\n",
        "\r\n",
        "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\")\r\n",
        "\r\n",
        "    features = np.zeros((0, 1024))\r\n",
        "    n = 100\r\n",
        "    l = int(len(messages) / n) if len(messages) % n == 0 else int(len(messages) / n) + 1\r\n",
        "    for i in range(l):\r\n",
        "\r\n",
        "        if (i + 1) * n < len(messages):\r\n",
        "            right = (i + 1) * n\r\n",
        "            embedds = elmo(messages[int(i * n) : right], signature=\"default\", as_dict=True)[\"default\"] \r\n",
        "        else:\r\n",
        "            embedds = elmo(messages[:len(messages) - int(i * n)], signature=\"default\", as_dict=True)[\"default\"] \r\n",
        "\r\n",
        "        with tf.Session() as sess:\r\n",
        "            sess.run(tf.global_variables_initializer())\r\n",
        "            embedds = sess.run(embedds)\r\n",
        "            features = np.concatenate([features, embedds])\r\n",
        "\r\n",
        "    return features"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrJEoo50xQVJ"
      },
      "source": [
        "#print(features)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Z_PvwyGCDS"
      },
      "source": [
        "def convert_labels(labels_raw):\r\n",
        "    '''\r\n",
        "    Transforms labels into numerical values;\r\n",
        "    Parameters:\r\n",
        "        labels_raw    -   array of text-labels;\r\n",
        "    Returns:\r\n",
        "        features    -   array of numerical labels;   \r\n",
        "    ''' \r\n",
        "\r\n",
        "    # add your code here\r\n",
        "    labels = []\r\n",
        "\r\n",
        "    for i in labels_raw:\r\n",
        "      if i == \"LEGI\":\r\n",
        "        labels.append(0)\r\n",
        "      elif i == \"SPAM\":\r\n",
        "        labels.append(1)\r\n",
        "      else:\r\n",
        "        pass\r\n",
        "    labels = np.asarray(labels)\r\n",
        "    return labels"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaaXXM1OSyMq"
      },
      "source": [
        "#print(labels)\r\n",
        "#print(len(labels))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4RGBF25GFfx",
        "outputId": "95051e3e-925d-4b38-bd96-e8d8bcc88133"
      },
      "source": [
        "features = messages2vectors(dataset[COLUMN_TEXT])\r\n",
        "labels = convert_labels(dataset[COLUMN_LABEL])\r\n",
        "print(features.shape)\r\n",
        "print(labels.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1231, 1024)\n",
            "(1231,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6T0pegqGOuo"
      },
      "source": [
        "def split_data(features, labels, ratio=0.7):\r\n",
        "    '''\r\n",
        "    Splits dataset into train/test parts using given ratio;\r\n",
        "    Parameters:\r\n",
        "        data    -   array of features;\r\n",
        "        labels  -   array of corresponding labels;\r\n",
        "        ratio   -   train/test size ratio;\r\n",
        "    Returns:\r\n",
        "        train_data      -   array of training features;   \r\n",
        "        train_labels    -   array of training labels; \r\n",
        "        test_data       -   array of testing features; \r\n",
        "        test_labels     -   array of testing labels; \r\n",
        "    '''    \r\n",
        "\r\n",
        "\r\n",
        "    positive_data = features[labels == 1] # all spam features\r\n",
        "    negative_data = features[labels == 0] # all legit features\r\n",
        "\r\n",
        "    # We shuffle arrays to get random samples later\r\n",
        "    random_indecies_positive = np.arange(positive_data.shape[0])\r\n",
        "    np.random.shuffle(random_indecies_positive)\r\n",
        "    random_indecies_negative = np.arange(negative_data.shape[0])\r\n",
        "    np.random.shuffle(random_indecies_negative)\r\n",
        "\r\n",
        "    n_positive_train = int(positive_data.shape[0] * ratio)\r\n",
        "    n_negative_train = int(negative_data.shape[0] * ratio)\r\n",
        "\r\n",
        "    # Training data are all indecies in 'ratio' part of shuffled indecies\r\n",
        "    train_data = np.concatenate([positive_data[random_indecies_positive[:n_positive_train]], \r\n",
        "                                negative_data[random_indecies_negative[:n_negative_train]]])\r\n",
        "    \r\n",
        "    train_labels = np.asarray([1] * n_positive_train + [0] * n_negative_train)\r\n",
        "\r\n",
        "    # Testing data are all indecies that remain\r\n",
        "    test_data = np.concatenate([positive_data[random_indecies_positive[n_positive_train:]], \r\n",
        "                                negative_data[random_indecies_negative[n_negative_train:]]])\r\n",
        "\r\n",
        "    test_labels = np.asarray([1] * (positive_data.shape[0]  - n_positive_train) + [0] * (negative_data.shape[0] - n_negative_train))\r\n",
        "\r\n",
        "    return train_data, train_labels, test_data, test_labels"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeF2UFLWP8N9"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOPYw1MC1pTY"
      },
      "source": [
        "For calculating FAR and FRR (Aka FPR and FNP) [p195 10.3](https://books.google.ca/books?id=Go4kBAAAQBAJ&pg=PA195&lpg=PA195&dq=FRR+vs+FNR&source=bl&ots=wZQadPKSIM&sig=fXrSks9EKc_ebkMaDuuXBMMqugM&hl=en&sa=X&ved=0ahUKEwjd9dDkvJrTAhXC5YMKHS1LAIIQ6AEITzAJ#v=onepage&q=FRR%20vs%20FNR&f=false) we can use 2(3) ways:\r\n",
        "\r\n",
        "\r\n",
        "> 1) FAR = FPR = FP/(FP + TN)\r\n",
        "\r\n",
        "> FRR = FNR = FN/(FN + TP)\r\n",
        "\r\n",
        "> were [tn, fp, fn, tp = sklearn.metrics.confusion_matrix(labels, predictions).ravel()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\r\n",
        "\r\n",
        "> 2) fpr, tpr, thresholds = sklearn.metrics.roc_curve(labels, predictions)\r\n",
        "\r\n",
        "> fnr = 1-tpr\r\n",
        "\r\n",
        "> fpr = far, fnr = frr\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9qUWXZbG-uU"
      },
      "source": [
        "\r\n",
        "def get_metrics(labels, predictions):\r\n",
        "    '''\r\n",
        "    Computes metrics;\r\n",
        "    Parameters:\r\n",
        "        labels    -   array of labels;\r\n",
        "        predictions  -   array of predictions;\r\n",
        "    Returns:\r\n",
        "        FAR -   False Acceptance Rate;\r\n",
        "        FRR -   False Rejection Rate;\r\n",
        "        FAR = FPR = FP/(FP + TN)\r\n",
        "        FRR = FNR = FN/(FN + TP)\r\n",
        "        where FP: False positive\r\n",
        "              FN: False Negative\r\n",
        "              TN: True Negative\r\n",
        "              TP: True Positive\r\n",
        "              TP = cm[0][0]\r\n",
        "              FP = cm[0][1]\r\n",
        "              FN = cm[1][0]\r\n",
        "              TN = cm[1][1]\r\n",
        "         \r\n",
        "    '''  \r\n",
        "    \r\n",
        "    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(labels, predictions).ravel()\r\n",
        "    print(\"tn, fp, fn, tp\", tn, fp, fn, tp)\r\n",
        "#\r\n",
        "    FAR = fp / (fp + tn) * 100\r\n",
        "    FRR = fn / (fn + tp) * 100\r\n",
        "#\r\n",
        "    #print('FAR, FRR',FAR, FRR)\r\n",
        "\r\n",
        "    #FAR, tpr, thresholds = sklearn.metrics.roc_curve(labels, predictions)\r\n",
        "    #FRR = 1-tpr\r\n",
        "    #print('FAR, FRR',FAR, FRR)\r\n",
        "    #\r\n",
        "    #FAR = (2 * sklearn.metrics.balanced_accuracy_score(labels, predictions)) - sklearn.metrics.recall_score(labels, predictions)\r\n",
        "    #FRR = 1 - sklearn.metrics.recall_score(labels, predictions)\r\n",
        "    \r\n",
        "    return FAR, FRR"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFUT2hQjQCw9"
      },
      "source": [
        "#Model initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwHHdk6pHDOp"
      },
      "source": [
        "classifierType = sklearn.ensemble.RandomForestClassifier\r\n",
        "hyperparameters = {'n_estimators' : 100,\r\n",
        "                'criterion' : 'gini',\r\n",
        "                'max_depth' : None,\r\n",
        "                'min_samples_split' : 2}"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaBWfuBbQNEN"
      },
      "source": [
        "# Model Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xcIklt9HLvk"
      },
      "source": [
        "def evaluate(classifierType, hyperparameters, features, labels):\r\n",
        "    '''\r\n",
        "    Splits dataset into train/test parts using given ratio;\r\n",
        "    Parameters:\r\n",
        "        classifierType      -   type of ML algorithm to use;\r\n",
        "        hyperparameters     -   dictionary of model's parameters;\r\n",
        "        features            -   array of features;\r\n",
        "        labels              -   array of labels\r\n",
        "    Returns:\r\n",
        "        trainFAR    -   False Acceptance Rate for train dataset;\r\n",
        "        trainFRR    -   False Rejection Rate for train dataset;\r\n",
        "        testFAR     -   False Acceptance Rate for test dataset;\r\n",
        "        testFRR    -   False Rejection Rate for test dataset;\r\n",
        "\r\n",
        "        train_data      -   array of training features;   \r\n",
        "        train_labels    -   array of training labels; \r\n",
        "        test_data       -   array of testing features; \r\n",
        "        test_labels     -   array of testing labels; \r\n",
        "        FAR = FPR = FP/(FP + TN)\r\n",
        "        FRR = FNR = FN/(FN + TP)\r\n",
        "        where FP: False positive\r\n",
        "              FN: False Negative\r\n",
        "              TN: True Negative\r\n",
        "              TP: True Positive\r\n",
        "    \r\n",
        "    '''    \r\n",
        "    \r\n",
        "    model = classifierType(**hyperparameters)\r\n",
        "\r\n",
        "    # Split data\r\n",
        "    # add your code here\r\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(features, labels)\r\n",
        "    #X_train, X_test, y_train, y_test train_data, train_labels, test_data, test_labels\r\n",
        "    print('Train set shape:', train_data.shape)\r\n",
        "    print('Train labels shape:', train_labels.shape)\r\n",
        "    print('Test set shape:', test_data.shape)\r\n",
        "    print('Test labels shape:', test_labels.shape)\r\n",
        "\r\n",
        "    #print(\"train data\", train_data)\r\n",
        "    #print(\"train labels\", train_labels)\r\n",
        "    #print(\"test data\", test_data) #binary\r\n",
        "    #print(\"test labels\", test_labels) #binary\r\n",
        "\r\n",
        "    # Fit your model\r\n",
        "    # add your code here\r\n",
        "    model.fit(train_data, train_labels)\r\n",
        "\r\n",
        "    # Make predictions for training dataset\r\n",
        "    # add your code here\r\n",
        "    pred = model.predict(train_data)\r\n",
        "    print('predict', pred.shape)\r\n",
        "    # Compute train FAR/FRR\r\n",
        "    # add your code here\r\n",
        "    trainFAR, trainFRR = get_metrics(train_labels, pred)\r\n",
        "    print('trainFAR, trainFRR',trainFAR, trainFRR)\r\n",
        "\r\n",
        "    # Make predictions for testing dataset\r\n",
        "    # add your code here\r\n",
        "    predictions_test = model.predict(test_data)\r\n",
        "\r\n",
        "    # Compute test FAR/FRR\r\n",
        "    # add your code here\r\n",
        "    testFAR, testFRR =get_metrics(test_labels, predictions_test)\r\n",
        "    print('testFAR, testFRR',testFAR, testFRR)\r\n",
        "\r\n",
        "\r\n",
        "    return trainFAR, trainFRR, testFAR, testFRR"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmE6wHA9HRtK",
        "outputId": "847761f9-8b8e-40d4-f02f-ad4e17656476"
      },
      "source": [
        "# Check if it works :)\r\n",
        "trainFAR, trainFRR, testFAR, testFRR = evaluate(classifierType, hyperparameters, features, labels)\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set shape: (923, 1024)\n",
            "Train labels shape: (923,)\n",
            "Test set shape: (308, 1024)\n",
            "Test labels shape: (308,)\n",
            "predict (923,)\n",
            "tn, fp, fn, tp 794 0 0 129\n",
            "trainFAR, trainFRR 0.0 0.0\n",
            "tn, fp, fn, tp 260 1 8 39\n",
            "testFAR, testFRR 0.38314176245210724 17.02127659574468\n",
            "Train:\n",
            "\tFAR: 0.0\n",
            "\tFRR: 0.0\n",
            "Test:\n",
            "\tFAR: 0.38314176245210724\n",
            "\tFRR: 17.02127659574468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj41g40zlW5F"
      },
      "source": [
        "# Final Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRdSvqKtl8C9"
      },
      "source": [
        " **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBqIuqiIHYHe"
      },
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(features, labels)\r\n",
        "#X_train, X_test, y_train, y_test"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw8rA68BlWO6"
      },
      "source": [
        "from sklearn import svm"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y6MtltbnKA4"
      },
      "source": [
        "clf = svm.SVC(kernel='linear')\r\n",
        "clf.fit(train_data, train_labels)\r\n",
        "test_labels_pred = clf.predict(test_data)\r\n",
        "train_labels_pred = clf.predict(train_data)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXqsw01FpFwG",
        "outputId": "b1aa1889-2e93-43cf-f23a-0e4dd987a21d"
      },
      "source": [
        "print(\"Accuracy test\", sklearn.metrics.accuracy_score(test_labels, test_labels_pred))\r\n",
        "print(\"Accuracy train\", sklearn.metrics.accuracy_score(train_labels, train_labels_pred))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy test 0.9772727272727273\n",
            "Accuracy train 0.9945828819068255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx4SezV1pge_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "affcc0da-81e9-4cdc-a412-3ec04276dc17"
      },
      "source": [
        "trainFAR, trainFRR = get_metrics(train_labels, train_labels_pred)\r\n",
        "testFAR, testFRR = get_metrics(test_labels, test_labels_pred)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tn, fp, fn, tp 783 5 0 135\n",
            "tn, fp, fn, tp 265 2 5 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SscudWHBqmS4",
        "outputId": "90ea6baf-6737-4d43-9028-edba3c633ce1"
      },
      "source": [
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:\n",
            "\tFAR: 0.6345177664974619\n",
            "\tFRR: 0.0\n",
            "Test:\n",
            "\tFAR: 0.7490636704119851\n",
            "\tFRR: 12.195121951219512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCM0Xdqjqy9O"
      },
      "source": [
        "**K-Nearest Neighbors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mY6mE71rSvU"
      },
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(features, labels)\r\n",
        "#X_train, X_test, y_train, y_test"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjNiFURurWeF"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuVuV9ziriDz",
        "outputId": "d19db529-9531-4b56-846a-0cf9da888219"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\r\n",
        "knn.fit(train_data, train_labels)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyDMrWhrmta"
      },
      "source": [
        "test_labels_pred = knn.predict(test_data)\r\n",
        "train_labels_pred = knn.predict(train_data)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2qwDWnyr6rU",
        "outputId": "7026c1ca-19ac-4571-a629-d53bab64ab37"
      },
      "source": [
        "print(\"Accuracy test\", sklearn.metrics.accuracy_score(test_labels, test_labels_pred))\r\n",
        "print(\"Accuracy train\", sklearn.metrics.accuracy_score(train_labels, train_labels_pred))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy test 0.9707792207792207\n",
            "Accuracy train 0.9794149512459371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc9UCQG2sCkU",
        "outputId": "e818b3b9-816f-4eb5-de35-b90c0cba4226"
      },
      "source": [
        "trainFAR, trainFRR = get_metrics(train_labels, train_labels_pred)\r\n",
        "testFAR, testFRR = get_metrics(test_labels, test_labels_pred)\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tn, fp, fn, tp 773 17 2 131\n",
            "tn, fp, fn, tp 257 8 1 42\n",
            "Train:\n",
            "\tFAR: 2.151898734177215\n",
            "\tFRR: 1.5037593984962405\n",
            "Test:\n",
            "\tFAR: 3.018867924528302\n",
            "\tFRR: 2.3255813953488373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4GJHUdjtwVM"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOMc8II3stkR"
      },
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(features, labels)\r\n",
        "#X_train, X_test, y_train, y_test"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr6KkcRTuC4g"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_5Rst5iuJ_0"
      },
      "source": [
        "lg = LogisticRegression()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYJmAppNuMNO",
        "outputId": "c4ea316d-f7b9-4220-be86-a488ad37ecd7"
      },
      "source": [
        "lg.fit(train_data, train_labels)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd-ivGmTuRzw"
      },
      "source": [
        "test_labels_pred = lg.predict(test_data)\r\n",
        "train_labels_pred = lg.predict(train_data)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggM6aCpFucyx",
        "outputId": "aafe04cb-01bc-4ffe-bab7-73902d79c25e"
      },
      "source": [
        "print(\"Accuracy test\", sklearn.metrics.accuracy_score(test_labels, test_labels_pred))\r\n",
        "print(\"Accuracy train\", sklearn.metrics.accuracy_score(train_labels, train_labels_pred))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy test 0.9902597402597403\n",
            "Accuracy train 0.9924160346695557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovbq20DJufVQ",
        "outputId": "0970331a-f5a4-4e8b-abf8-2cd5ac70dffc"
      },
      "source": [
        "trainFAR, trainFRR = get_metrics(train_labels, train_labels_pred)\r\n",
        "testFAR, testFRR = get_metrics(test_labels, test_labels_pred)\r\n",
        "print('Train:')\r\n",
        "print('\\tFAR:', trainFAR)\r\n",
        "print('\\tFRR:', trainFRR)\r\n",
        "\r\n",
        "print('Test:')\r\n",
        "print('\\tFAR:', testFAR)\r\n",
        "print('\\tFRR:', testFRR)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tn, fp, fn, tp 793 5 2 123\n",
            "tn, fp, fn, tp 256 1 2 49\n",
            "Train:\n",
            "\tFAR: 0.6265664160401002\n",
            "\tFRR: 1.6\n",
            "Test:\n",
            "\tFAR: 0.38910505836575876\n",
            "\tFRR: 3.9215686274509802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky7_Vh1Jui9G"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": []
    }
  ]
}